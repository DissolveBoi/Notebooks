# 线性神经网络

## 3.4 softmax回归

### 3.4.1 分类问题

- 独热编码（one-hot encoding）：一个分量和类别一样多的向量，对应的分量设置为1,其他的所有分量为0

### 3.4.2 网络架构

- 需要一个多输出的模型，有几层就需要几个；
- 为了解决分类问题，需要和输出一样多的仿射函数；每个输出对应于它自己的仿射函数

  > 仿射函数（affine function）即由 1 阶多项式构成的函数，一般形式为:$f ( x ) = A x + b$。这里，$A$是一个$m\times m$矩阵，$x$是一个$k$维向量，$b$是一个$m$维向量，实际上反映了一种从$k$维到$m$维的空间映射关系。

![[Pasted image 20231011191003.png]]
![[Pasted image 20231011191055.png]]

- 我们仍然使用线性代数符号来表示：$\boldsymbol{o}=\boldsymbol{W}\boldsymbol{x}+\boldsymbol{b}$

### 3.4.4 softmax运算

- 我们希望模型的输出$\hat{y}_j$可以视为属于$j$类的概率，然后选择概率最大的类别作为输出
- 为了使得最终输出的概率值总和为1，我们可以使用$softmax$函数$\hat{\boldsymbol{y}} = softmax(\boldsymbol{o})$，其中：

$$
\hat{y_j} = \frac{\exp{o_j}}{\sum_k\exp(o_k)}
$$

### 3.4.5 矢量化操作（略）

### 3.4.6 损失函数

- softmax函数给出了一个向量$\boldsymbol{\hat{y}}$，我们可以将其视为“对给定任意输入
